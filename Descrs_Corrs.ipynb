{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from importlib import reload\n",
    "import extract_features\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns\n",
    "import results_functions\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from scipy.stats import wilcoxon\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "json_path_project = 'S:\\\\AG\\\\AG-Bewegungsstoerungen-II\\\\LFP\\\\PROJECTS\\BATTERY\\\\'\n",
    "json_path_onedrive = 'C:\\\\Users\\\\mathiopv\\\\OneDrive - Charité - Universitätsmedizin Berlin\\\\BATTERY_LIFE\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make descriptive boxplots for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:\\Dokumente\\PROJECTS\\BATTERY_LIFE\\PerceptBatteryLife\\PerceptIPGProgression\\results_functions.py:58: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  means = this_df.mean()\n",
      "t:\\Dokumente\\PROJECTS\\BATTERY_LIFE\\PerceptBatteryLife\\PerceptIPGProgression\\results_functions.py:59: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  stds = this_df.std()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwith open(os.path.join(directory,\\n    \\'Means_FU0M.pkl\\'), \"rb\") as file:\\n    val_dat = pickle.load(file)\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = os.path.join(json_path_onedrive,\n",
    "    'results', 'Avg_Features', 'Avg_Features_Tbls' )\n",
    "\n",
    "dir_saving = os.path.join(json_path_onedrive,\n",
    "    'results', 'Avg_Features', 'test_results' )\n",
    "reload(results_functions)\n",
    "%matplotlib qt\n",
    "saving = 1\n",
    "df_fu0m, df_fu3m, df_fu12m, all_dfs = results_functions.get_descriptives(directory, dir_saving, saving)\n",
    "\n",
    "'''\n",
    "with open(os.path.join(directory,\n",
    "    'Means_FU0M.pkl'), \"rb\") as file:\n",
    "    val_dat = pickle.load(file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376.89\n",
      "40.03\n"
     ]
    }
   ],
   "source": [
    "print(np.round(np.mean(df_fu12m['AccTimeSinceImplant_Days']), decimals = 2))\n",
    "print(np.round(np.std(df_fu12m['AccTimeSinceImplant_Days']), decimals = 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Battery boxplot\n",
    "all_dfs.head()\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5,5))\n",
    "sns.boxplot(data=all_dfs, x=\"TimePoint\", y='FirstBatVal',fliersize=0, \n",
    "            boxprops=dict(facecolor='pink', edgecolor='darkred', linewidth = 3),\n",
    "            whiskerprops=dict(color='darkred', linewidth = 4), width = 0.5, dodge = 0.2)\n",
    "\n",
    "sns.stripplot(data=all_dfs, x='TimePoint', y='FirstBatVal', marker='o',\n",
    "                jitter = True, size = 12, alpha = 0.4, color = 'firebrick')\n",
    "axs.set_ylabel('IPG Battery [%]')\n",
    "plt.savefig(os.path.join(dir_saving, 'BatteryPercentageTP'), dpi = 200)\n",
    "plt.savefig(os.path.join(dir_saving, 'BatteryPercentageTP.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubID</th>\n",
       "      <th>TimePoint</th>\n",
       "      <th>Telemetry_AllSec</th>\n",
       "      <th>TelemDurSumSecRes</th>\n",
       "      <th>TelemDurSumSecWard</th>\n",
       "      <th>SensDurSumSec</th>\n",
       "      <th>FirstBatVal</th>\n",
       "      <th>LastBatVal</th>\n",
       "      <th>AccTimeSinceImplant_Days</th>\n",
       "      <th>Electrode</th>\n",
       "      <th>Telemetry_AllMin</th>\n",
       "      <th>TelemDurSumSMinRes</th>\n",
       "      <th>TelemDurSumMinWard</th>\n",
       "      <th>SensDurSumMin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sub002</td>\n",
       "      <td>FU0M</td>\n",
       "      <td>2412.108</td>\n",
       "      <td>2184.108</td>\n",
       "      <td>228.0</td>\n",
       "      <td>584.716</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3389</td>\n",
       "      <td>40.201800</td>\n",
       "      <td>36.401800</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>9.745267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sub005</td>\n",
       "      <td>FU0M</td>\n",
       "      <td>3005.000</td>\n",
       "      <td>2062.000</td>\n",
       "      <td>128.0</td>\n",
       "      <td>821.772</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3389</td>\n",
       "      <td>50.083333</td>\n",
       "      <td>34.366667</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>13.696200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sub006</td>\n",
       "      <td>FU0M</td>\n",
       "      <td>331.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>331.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3389</td>\n",
       "      <td>5.516667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.516667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sub007</td>\n",
       "      <td>FU0M</td>\n",
       "      <td>1876.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1451.0</td>\n",
       "      <td>254.356</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3389</td>\n",
       "      <td>31.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.183333</td>\n",
       "      <td>4.239267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sub008</td>\n",
       "      <td>FU0M</td>\n",
       "      <td>171.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3389</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SubID TimePoint  Telemetry_AllSec  TelemDurSumSecRes  TelemDurSumSecWard  \\\n",
       "0  Sub002      FU0M          2412.108           2184.108               228.0   \n",
       "0  Sub005      FU0M          3005.000           2062.000               128.0   \n",
       "0  Sub006      FU0M           331.000              0.000               331.0   \n",
       "0  Sub007      FU0M          1876.000              0.000              1451.0   \n",
       "0  Sub008      FU0M           171.000              0.000               171.0   \n",
       "\n",
       "   SensDurSumSec  FirstBatVal  LastBatVal  AccTimeSinceImplant_Days Electrode  \\\n",
       "0        584.716         99.0        99.0                       0.0      3389   \n",
       "0        821.772         99.0        99.0                       0.0      3389   \n",
       "0          0.000         99.0        99.0                       0.0      3389   \n",
       "0        254.356         99.0        99.0                       0.0      3389   \n",
       "0          0.000         99.0        99.0                       0.0      3389   \n",
       "\n",
       "   Telemetry_AllMin  TelemDurSumSMinRes  TelemDurSumMinWard  SensDurSumMin  \n",
       "0         40.201800           36.401800            3.800000       9.745267  \n",
       "0         50.083333           34.366667            2.133333      13.696200  \n",
       "0          5.516667            0.000000            5.516667       0.000000  \n",
       "0         31.266667            0.000000           24.183333       4.239267  \n",
       "0          2.850000            0.000000            2.850000       0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dfs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pairwise Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fus_df = pd.read_excel(os.path.join(\n",
    "    json_path_onedrive, 'results', 'Avg_Features', 'test_results','All_FollowUp_dfs.xlsx'\n",
    ")) \n",
    "\n",
    "all_fus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the results for each column\n",
    "all_columns = ['Telemetry_AllMin', 'SensDurSumMin']\n",
    "wilcoxon_results = {}\n",
    "\n",
    "# List of time points to compare\n",
    "time_points = ['FU0M', 'FU3M', 'FU12M']\n",
    "\n",
    "# Perform pairwise Wilcoxon signed-rank tests and store the results for each column\n",
    "for column in all_columns:\n",
    "    comparisons_results = {}\n",
    "    for i in range(len(time_points)-1):\n",
    "        for j in range(i+1, len(time_points)):\n",
    "            tp1, tp2 = time_points[i], time_points[j]\n",
    "            x1 = all_fus_df.loc[all_fus_df['TimePoint'] == tp1,column]#all_fus_df.loc[all_fus_df['TimePoint'] == tp1, column]\n",
    "            x2 = all_fus_df.loc[all_fus_df['TimePoint'] ==  tp2, column]#all_fus_df.loc[all_fus_df['TimePoint'] == tp2, column]\n",
    "\n",
    "            statistic, p_value = wilcoxon(x1, x2, nan_policy='omit')\n",
    "\n",
    "            comparison_name = f\"{column}_{tp1}-{tp2}\"\n",
    "\n",
    "\n",
    "            comparisons_results[comparison_name] = {'Statistic': statistic, 'Original_p-values': p_value}\n",
    "    \n",
    "    wilcoxon_results[column] = comparisons_results\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "results_df = pd.DataFrame({(column, key): value for column, values in wilcoxon_results.items() for key, value in values.items()}).T\n",
    "\n",
    "\n",
    "## Adjust for multiple comparisons\n",
    "reject, corrected_p_values, _, _ = multipletests(results_df['Original_p-values'],\n",
    "                                                 alpha = 0.05, \n",
    "                                                 method='bonferroni')\n",
    "results_df['Corrected_p-values'] = corrected_p_values\n",
    "\n",
    "significance_conds = [\n",
    "    (results_df['Corrected_p-values'] <= 0.001),\n",
    "    (results_df['Corrected_p-values'] <= 0.01),\n",
    "    (results_df['Corrected_p-values'] < 0.05),\n",
    "    (results_df['Corrected_p-values'] >= 0.05)\n",
    "]\n",
    "\n",
    "values = ['***', '**', '*', 'n.s.']\n",
    "\n",
    "results_df['Significance_multcomp'] = np.select(significance_conds, values, default = 'Other')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel(os.path.join(\n",
    "    json_path_onedrive, 'results', 'Avg_Features', 'test_results','PairwiseComps.xlsx'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make correlations with TEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_Feat = os.path.join(json_path_onedrive,\n",
    "    'results', 'Avg_Features', 'Avg_Features_Tbls')\n",
    "\n",
    "directory_TEED = os.path.join(json_path_onedrive,\n",
    "    'results', 'Stim_pars', 'TEED')\n",
    "\n",
    "directory_corrs = os.path.join(json_path_onedrive,\n",
    "    'results', 'Correlations')\n",
    "\n",
    "saving = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(results_functions)\n",
    "%matplotlib qt\n",
    "corr_df  = results_functions.get_battery_corr_df(directory_Feat, \n",
    "                                                directory_TEED, \n",
    "                                                directory_corrs, \n",
    "                                                saving)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify and remove Outlierts with the IQR Method\n",
    "corr_df = pd.read_csv(os.path.join(json_path_onedrive, 'results','MultivariateAnal',\n",
    "                                   'Corr_df.csv'), index_col=None)\n",
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IQR Method (Interquartile Range):\n",
    "\n",
    "It uses the range between the first quartile (Q1) and the third quartile (Q3) to identify outliers.\n",
    "\n",
    "Data points outside the range [Q1 - 1.5 * IQR, Q3 + 1.5 * IQR] are considered outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_of_int = ['Telemetry_AllSec_div', 'SensDurSumSec_div', 'Chronic_12mfu_Days', 'TEED']\n",
    "\n",
    "for val in values_of_int:\n",
    "    data = corr_df[val]\n",
    "    \n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    iqr = q3 - q1\n",
    "    outliers = (data < q1 - 1.5 * iqr) | (data > q3 + 1.5 * iqr)\n",
    "    outlier_subids = corr_df.loc[outliers, 'SubID'].tolist()\n",
    "    \n",
    "    print(f'Outliers for {val} is {tuple(outlier_subids)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_corrs = os.path.join(json_path_onedrive,\n",
    "    'results', 'Correlations')\n",
    "\n",
    "reload(results_functions)\n",
    "saving = 0\n",
    "filtered_corr_df = corr_df[~corr_df['SubID'].isin(['Sub015','Sub021', 'Sub029', 'Sub030'])]\n",
    "correlation_stats = results_functions.corrs_scatters(filtered_corr_df, saving, directory_corrs)\n",
    "#correlation_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Correct the spearman correlations for multiple comparisons\n",
    "\n",
    "corrs_pvalues = [item['p-value'] for item in list(correlation_stats.values())]\n",
    "\n",
    "reject, corrected_p_values, _, _ = multipletests(corrs_pvalues,\n",
    "                                                 alpha = 0.05, \n",
    "                                                 method='bonferroni')\n",
    "\n",
    "corrected_p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple Linear Regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Specify the formula for the mixed-effects model\n",
    "filtered_corr_df[['Telemetry_AllSec_div', 'SensDurSumSec_div', 'Chronic_12mfu_Days', 'TEED']] = filtered_corr_df[['Telemetry_AllSec_div', 'SensDurSumSec_div', 'Chronic_12mfu_Days', 'TEED']].astype(float)\n",
    "X = filtered_corr_df[['Telemetry_AllSec_div', 'SensDurSumSec_div', 'Chronic_12mfu_Days', 'TEED']]\n",
    "X = sm.add_constant(X)  # add a constant term for the intercept\n",
    "y = filtered_corr_df['Battery_12mfu']\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coefficients/Parameter estimates\n",
    "model.params\n",
    "#const = intercept\n",
    "#coefficient for TEED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "coefficients = model.params\n",
    "\n",
    "xlabels = ['Total Telemetry Duration [min]',\n",
    "           'Total Active Sensing Duration [min]',\n",
    "           'Total Chronic Sensing Duration [days]',\n",
    "           'TEED [Joules/sec]']\n",
    "\n",
    "# Scatterplots with regression lines\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "for i, var in enumerate(X.columns[1:]):  # Exclude the constant term\n",
    "    row, col = divmod(i, 2)\n",
    "    ax = axes[row, col]\n",
    "\n",
    "    # Scatterplot\n",
    "    ax.scatter(X[var], y, alpha=0.5, s = 80)\n",
    "\n",
    "    # Regression line\n",
    "    m, b = np.polyfit(X[var], y, 1)\n",
    "    ax.plot(X[var], m*X[var]+b, linewidth = 2)\n",
    "    \n",
    "    ax.set_xlabel(xlabels[i])\n",
    "    ax.set_ylabel('IPG Battery [%]')\n",
    "    #ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join(json_path_onedrive, 'results','MultivariateAnal', 'MultiVarScatters'), dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = filtered_corr_df['Telemetry_AllSec_div']\n",
    "y = filtered_corr_df['TEED']\n",
    "\n",
    "plt.scatter(x,y)\n",
    "stats = stats.spearmanr(x,y, nan_policy = 'omit')\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test assumptions for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Assumptions:\n",
    "import seaborn as sns\n",
    "\n",
    "#1. Linearity and \n",
    "residuals = model2.resid\n",
    "fitted_values = model2.fittedvalues\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].scatter(fitted_values, residuals)\n",
    "axs[0].set_xlabel('Fitted Values')\n",
    "axs[0].set_ylabel('Residuals')\n",
    "axs[0].set_title('Residuals vs. Fitted Values Plot')\n",
    "\n",
    "#Interpretation: Check for a random scatter of points with no discernible pattern. \n",
    "# A pattern may indicate non-linearity or heteroscedasticity.\n",
    "\n",
    "#2. Homoscedasticity\n",
    "axs[1].scatter(fitted_values, abs(np.sqrt(np.abs(residuals))))\n",
    "axs[1].set_xlabel('Fitted Values')\n",
    "axs[1].set_ylabel('Square Root of Standardized Residuals')\n",
    "axs[1].set_title('Scale-Location Plot')\n",
    "plt.show()\n",
    "#Interpretation: Check for a horizontal line with no clear pattern. \n",
    "# A funnel-shaped pattern may indicate heteroscedasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Normality of Residuals\n",
    "sm.qqplot(residuals, line='s')\n",
    "#Interpretation: Points close to the diagonal \n",
    "# line suggest that residuals are approximately normally distributed.\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "stat, p_value = shapiro(residuals)\n",
    "\n",
    "print(f'Shapiro-Wilk Test Statistic: {stat:.4f}, p-value: {p_value:.4f}')\n",
    "#small p-value suggests that the residuals are not normally distributed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
