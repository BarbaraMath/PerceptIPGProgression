{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from importlib import reload\n",
    "import extract_features\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns\n",
    "import results_functions\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from scipy.stats import wilcoxon\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "json_path_project = 'S:\\\\AG\\\\AG-Bewegungsstoerungen-II\\\\LFP\\\\PROJECTS\\BATTERY\\\\'\n",
    "json_path_onedrive = 'C:\\\\Users\\\\mathiopv\\\\OneDrive - Charité - Universitätsmedizin Berlin\\\\BATTERY_LIFE\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make descriptive boxplots for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(json_path_onedrive,\n",
    "    'results', 'Avg_Features', 'Avg_Features_Tbls' )\n",
    "\n",
    "dir_saving = os.path.join(json_path_onedrive,\n",
    "    'results', 'Avg_Features', 'test_results' )\n",
    "reload(results_functions)\n",
    "%matplotlib qt\n",
    "saving = 1\n",
    "df_fu0m, df_fu3m, df_fu12m = results_functions.get_descriptives(directory, dir_saving, saving)\n",
    "\n",
    "'''\n",
    "with open(os.path.join(directory,\n",
    "    'Means_FU0M.pkl'), \"rb\") as file:\n",
    "    val_dat = pickle.load(file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pairwise Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fus_df = pd.read_csv(os.path.join(\n",
    "    json_path_onedrive, 'results', 'Avg_Features', 'test_results','All_FollowUp_dfs.csv'\n",
    ")) \n",
    "\n",
    "all_fus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the results for each column\n",
    "all_columns = ['Telemetry_AllMin', 'TelemDurSumSMinRes', 'TelemDurSumMinWard', 'SensDurSumMin']\n",
    "wilcoxon_results = {}\n",
    "\n",
    "# List of time points to compare\n",
    "time_points = ['FU0M', 'FU3M', 'FU12M']\n",
    "\n",
    "# Perform pairwise Wilcoxon signed-rank tests and store the results for each column\n",
    "for column in all_columns:\n",
    "    comparisons_results = {}\n",
    "    for i in range(len(time_points)-1):\n",
    "        for j in range(i+1, len(time_points)):\n",
    "            tp1, tp2 = time_points[i], time_points[j]\n",
    "            x1 = all_fus_df.loc[all_fus_df['TimePoint'] == tp1, column]\n",
    "            x2 = all_fus_df.loc[all_fus_df['TimePoint'] == tp2, column]\n",
    "\n",
    "            statistic, p_value = wilcoxon(x1, x2)\n",
    "\n",
    "            comparison_name = f\"{column}_{tp1}-{tp2}\"\n",
    "\n",
    "\n",
    "            comparisons_results[comparison_name] = {'Statistic': statistic, 'Original_p-values': p_value}\n",
    "    \n",
    "    wilcoxon_results[column] = comparisons_results\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "results_df = pd.DataFrame({(column, key): value for column, values in wilcoxon_results.items() for key, value in values.items()}).T\n",
    "\n",
    "\n",
    "## Adjust for multiple comparisons\n",
    "reject, corrected_p_values, _, _ = multipletests(results_df['Original_p-values'],\n",
    "                                                 alpha = 0.05, \n",
    "                                                 method='bonferroni')\n",
    "results_df['Corrected_p-values'] = corrected_p_values\n",
    "\n",
    "significance_conds = [\n",
    "    (results_df['Corrected_p-values'] <= 0.001),\n",
    "    (results_df['Corrected_p-values'] <= 0.01),\n",
    "    (results_df['Corrected_p-values'] < 0.05),\n",
    "    (results_df['Corrected_p-values'] >= 0.05)\n",
    "]\n",
    "\n",
    "values = ['***', '**', '*', 'n.s.']\n",
    "\n",
    "results_df['Significance_multcomp'] = np.select(significance_conds, values, default = 'Other')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel(os.path.join(\n",
    "    json_path_onedrive, 'results', 'Avg_Features', 'test_results','PairwiseComps.xlsx'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fus_df[(all_fus_df['TimePoint'] == 'FU0M') & (all_fus_df['Electrode'] == 'SenSight')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make correlations with TEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_Feat = os.path.join(json_path_onedrive,\n",
    "    'results', 'Avg_Features', 'Avg_Features_Tbls')\n",
    "\n",
    "directory_TEED = os.path.join(json_path_onedrive,\n",
    "    'results', 'Stim_pars', 'TEED')\n",
    "\n",
    "directory_corrs = os.path.join(json_path_onedrive,\n",
    "    'results', 'Correlations')\n",
    "\n",
    "saving = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(results_functions)\n",
    "%matplotlib qt\n",
    "corr_df  = results_functions.get_battery_corr_df(directory_Feat, \n",
    "                                                directory_TEED, \n",
    "                                                directory_corrs, \n",
    "                                                saving)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(results_functions)\n",
    "saving = 1\n",
    "correlation_stats = results_functions.corrs_scatters(corr_df, saving, directory_corrs)\n",
    "#correlation_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Correct the spearman correlations for multiple comparisons\n",
    "\n",
    "corrs_pvalues = [item['p-value'] for item in list(correlation_stats.values())]\n",
    "\n",
    "reject, corrected_p_values, _, _ = multipletests(corrs_pvalues,\n",
    "                                                 alpha = 0.05, \n",
    "                                                 method='bonferroni')\n",
    "\n",
    "corrected_p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple Linear Regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Specify the formula for the mixed-effects model\n",
    "corr_df[['Telemetry_AllSec_div', 'SensDurSumSec_div', 'Chronic_12mfu_Days', 'TEED']] = corr_df[['Telemetry_AllSec_div', 'SensDurSumSec_div', 'Chronic_12mfu_Days', 'TEED']].astype(float)\n",
    "X = corr_df[['Telemetry_AllSec_div', 'SensDurSumSec_div', 'Chronic_12mfu_Days', 'TEED']]\n",
    "X = sm.add_constant(X)  # add a constant term for the intercept\n",
    "y = corr_df['Battery_12mfu']\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression with TEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then Run a simplified linear regression only with the significant value TEED:\n",
    "\n",
    "X = sm.add_constant(corr_df['TEED'])  # Assuming 'TEED' is the independent variable\n",
    "y = corr_df['Battery_12mfu']           # Assuming 'Battery_12mfu' is the dependent variable\n",
    "\n",
    "# Fit the simple linear regression model\n",
    "model2 = sm.OLS(y, X).fit()\n",
    "\n",
    "# Display the model summary\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coefficients/Parameter estimates\n",
    "model2.params\n",
    "#const = intercept\n",
    "#coefficient for TEED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the model\n",
    "X_teeds = sm.add_constant(corr_df['TEED'])\n",
    "y_predicted = model2.predict(X_teeds)\n",
    "\n",
    "plt.scatter(corr_df['TEED'], corr_df['Battery_12mfu'], label='Actual Data')\n",
    "plt.plot(corr_df['TEED'], y_predicted, color='red', label='Regression Line')\n",
    "plt.xlabel('TEED')\n",
    "plt.ylabel('Battery_12mfu')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test assumptions for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Assumptions:\n",
    "import seaborn as sns\n",
    "\n",
    "#1. Linearity and \n",
    "residuals = model2.resid\n",
    "fitted_values = model2.fittedvalues\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].scatter(fitted_values, residuals)\n",
    "axs[0].set_xlabel('Fitted Values')\n",
    "axs[0].set_ylabel('Residuals')\n",
    "axs[0].set_title('Residuals vs. Fitted Values Plot')\n",
    "\n",
    "#Interpretation: Check for a random scatter of points with no discernible pattern. \n",
    "# A pattern may indicate non-linearity or heteroscedasticity.\n",
    "\n",
    "#2. Homoscedasticity\n",
    "axs[1].scatter(fitted_values, abs(np.sqrt(np.abs(residuals))))\n",
    "axs[1].set_xlabel('Fitted Values')\n",
    "axs[1].set_ylabel('Square Root of Standardized Residuals')\n",
    "axs[1].set_title('Scale-Location Plot')\n",
    "plt.show()\n",
    "#Interpretation: Check for a horizontal line with no clear pattern. \n",
    "# A funnel-shaped pattern may indicate heteroscedasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Normality of Residuals\n",
    "sm.qqplot(residuals, line='s')\n",
    "#Interpretation: Points close to the diagonal \n",
    "# line suggest that residuals are approximately normally distributed.\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "stat, p_value = shapiro(residuals)\n",
    "\n",
    "print(f'Shapiro-Wilk Test Statistic: {stat:.4f}, p-value: {p_value:.4f}')\n",
    "#small p-value suggests that the residuals are not normally distributed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
