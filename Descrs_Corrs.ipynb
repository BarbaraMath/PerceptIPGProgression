{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from importlib import reload\n",
    "import extract_features\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns\n",
    "import results_functions\n",
    "from scipy import stats\n",
    "import pickle\n",
    "from scipy.stats import wilcoxon\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "\n",
    "json_path_project = 'S:\\\\AG\\\\AG-Bewegungsstoerungen-II\\\\LFP\\\\PROJECTS\\BATTERY\\\\'\n",
    "json_path_onedrive = 'C:\\\\Users\\\\mathiopv\\\\OneDrive - Charité - Universitätsmedizin Berlin\\\\BATTERY_LIFE\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make descriptive boxplots for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.path.join(json_path_onedrive,\n",
    "    'results', 'Avg_Features', 'Avg_Features_Tbls' )\n",
    "\n",
    "dir_saving = os.path.join(json_path_onedrive,\n",
    "    'results', 'Avg_Features', 'test_results' )\n",
    "reload(results_functions)\n",
    "%matplotlib qt\n",
    "saving = 1\n",
    "df_fu0m, df_fu3m, df_fu12m, all_dfs = results_functions.get_descriptives(directory, dir_saving, saving)\n",
    "\n",
    "'''\n",
    "with open(os.path.join(directory,\n",
    "    'Means_FU0M.pkl'), \"rb\") as file:\n",
    "    val_dat = pickle.load(file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Battery boxplot\n",
    "all_dfs.head()\n",
    "fig, axs = plt.subplots(1, 1, figsize=(5,5))\n",
    "sns.boxplot(data=all_dfs, x=\"TimePoint\", y='FirstBatVal',fliersize=0, \n",
    "            boxprops=dict(facecolor='pink', edgecolor='mediumvioletred', linewidth = 4),\n",
    "            whiskerprops=dict(color='mediumvioletred', linewidth = 4), width = 0.5, dodge = 0.2)\n",
    "\n",
    "sns.stripplot(data=all_dfs, x='TimePoint', y='FirstBatVal', marker='o',\n",
    "                jitter = True, size = 11, alpha = 0.4, color = 'darkmagenta')\n",
    "\n",
    "plt.savefig(os.path.join(dir_saving, 'BatteryPercentageTP'), dpi = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pairwise Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fus_df = pd.read_excel(os.path.join(\n",
    "    json_path_onedrive, 'results', 'Avg_Features', 'test_results','All_FollowUp_dfs.xlsx'\n",
    ")) \n",
    "\n",
    "all_fus_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the results for each column\n",
    "all_columns = ['Telemetry_AllMin', 'SensDurSumMin']\n",
    "wilcoxon_results = {}\n",
    "\n",
    "# List of time points to compare\n",
    "time_points = ['FU0M', 'FU3M', 'FU12M']\n",
    "\n",
    "# Perform pairwise Wilcoxon signed-rank tests and store the results for each column\n",
    "for column in all_columns:\n",
    "    comparisons_results = {}\n",
    "    for i in range(len(time_points)-1):\n",
    "        for j in range(i+1, len(time_points)):\n",
    "            tp1, tp2 = time_points[i], time_points[j]\n",
    "            x1 = all_fus_df.loc[all_fus_df['TimePoint'] == tp1,column]#all_fus_df.loc[all_fus_df['TimePoint'] == tp1, column]\n",
    "            x2 = all_fus_df.loc[all_fus_df['TimePoint'] ==  tp2, column]#all_fus_df.loc[all_fus_df['TimePoint'] == tp2, column]\n",
    "\n",
    "            statistic, p_value = wilcoxon(x1, x2, nan_policy='omit')\n",
    "\n",
    "            comparison_name = f\"{column}_{tp1}-{tp2}\"\n",
    "\n",
    "\n",
    "            comparisons_results[comparison_name] = {'Statistic': statistic, 'Original_p-values': p_value}\n",
    "    \n",
    "    wilcoxon_results[column] = comparisons_results\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "results_df = pd.DataFrame({(column, key): value for column, values in wilcoxon_results.items() for key, value in values.items()}).T\n",
    "\n",
    "\n",
    "## Adjust for multiple comparisons\n",
    "reject, corrected_p_values, _, _ = multipletests(results_df['Original_p-values'],\n",
    "                                                 alpha = 0.05, \n",
    "                                                 method='bonferroni')\n",
    "results_df['Corrected_p-values'] = corrected_p_values\n",
    "\n",
    "significance_conds = [\n",
    "    (results_df['Corrected_p-values'] <= 0.001),\n",
    "    (results_df['Corrected_p-values'] <= 0.01),\n",
    "    (results_df['Corrected_p-values'] < 0.05),\n",
    "    (results_df['Corrected_p-values'] >= 0.05)\n",
    "]\n",
    "\n",
    "values = ['***', '**', '*', 'n.s.']\n",
    "\n",
    "results_df['Significance_multcomp'] = np.select(significance_conds, values, default = 'Other')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel(os.path.join(\n",
    "    json_path_onedrive, 'results', 'Avg_Features', 'test_results','PairwiseComps.xlsx'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make correlations with TEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_Feat = os.path.join(json_path_onedrive,\n",
    "    'results', 'Avg_Features', 'Avg_Features_Tbls')\n",
    "\n",
    "directory_TEED = os.path.join(json_path_onedrive,\n",
    "    'results', 'Stim_pars', 'TEED')\n",
    "\n",
    "directory_corrs = os.path.join(json_path_onedrive,\n",
    "    'results', 'Correlations')\n",
    "\n",
    "saving = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(results_functions)\n",
    "%matplotlib qt\n",
    "corr_df  = results_functions.get_battery_corr_df(directory_Feat, \n",
    "                                                directory_TEED, \n",
    "                                                directory_corrs, \n",
    "                                                saving)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify and remove Outlierts with the IQR Method\n",
    "corr_df = pd.read_csv(os.path.join(json_path_onedrive, 'results','MultivariateAnal',\n",
    "                                   'Corr_df.csv'), index_col=None)\n",
    "corr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IQR Method (Interquartile Range):\n",
    "\n",
    "It uses the range between the first quartile (Q1) and the third quartile (Q3) to identify outliers.\n",
    "\n",
    "Data points outside the range [Q1 - 1.5 * IQR, Q3 + 1.5 * IQR] are considered outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_of_int = ['Telemetry_AllSec_div', 'SensDurSumSec_div', 'Chronic_12mfu_Days', 'TEED']\n",
    "\n",
    "for val in values_of_int:\n",
    "    data = corr_df[val]\n",
    "    \n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    iqr = q3 - q1\n",
    "    outliers = (data < q1 - 1.5 * iqr) | (data > q3 + 1.5 * iqr)\n",
    "    outlier_subids = corr_df.loc[outliers, 'SubID'].tolist()\n",
    "    \n",
    "    print(f'Outliers for {val} is {tuple(outlier_subids)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_corrs = os.path.join(json_path_onedrive,\n",
    "    'results', 'Correlations')\n",
    "\n",
    "reload(results_functions)\n",
    "saving = 0\n",
    "filtered_corr_df = corr_df[~corr_df['SubID'].isin(['Sub015','Sub021', 'Sub029', 'Sub030'])]\n",
    "correlation_stats = results_functions.corrs_scatters(filtered_corr_df, saving, directory_corrs)\n",
    "#correlation_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Correct the spearman correlations for multiple comparisons\n",
    "\n",
    "corrs_pvalues = [item['p-value'] for item in list(correlation_stats.values())]\n",
    "\n",
    "reject, corrected_p_values, _, _ = multipletests(corrs_pvalues,\n",
    "                                                 alpha = 0.05, \n",
    "                                                 method='bonferroni')\n",
    "\n",
    "corrected_p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple Linear Regression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Specify the formula for the mixed-effects model\n",
    "filtered_corr_df[['Telemetry_AllSec_div', 'SensDurSumSec_div', 'Chronic_12mfu_Days', 'TEED']] = filtered_corr_df[['Telemetry_AllSec_div', 'SensDurSumSec_div', 'Chronic_12mfu_Days', 'TEED']].astype(float)\n",
    "X = filtered_corr_df[['Telemetry_AllSec_div', 'SensDurSumSec_div', 'Chronic_12mfu_Days', 'TEED']]\n",
    "X = sm.add_constant(X)  # add a constant term for the intercept\n",
    "y = filtered_corr_df['Battery_12mfu']\n",
    "\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coefficients/Parameter estimates\n",
    "model.params\n",
    "#const = intercept\n",
    "#coefficient for TEED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "coefficients = model.params\n",
    "\n",
    "xlabels = ['Total Telemetry Duration [min]',\n",
    "           'Total Active Sensing Duration [min]',\n",
    "           'Total Chronic Sensing Duration [days]',\n",
    "           'TEED [Joules/sec]']\n",
    "\n",
    "# Scatterplots with regression lines\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "for i, var in enumerate(X.columns[1:]):  # Exclude the constant term\n",
    "    row, col = divmod(i, 2)\n",
    "    ax = axes[row, col]\n",
    "\n",
    "    # Scatterplot\n",
    "    ax.scatter(X[var], y, alpha=0.5, s = 80)\n",
    "\n",
    "    # Regression line\n",
    "    m, b = np.polyfit(X[var], y, 1)\n",
    "    ax.plot(X[var], m*X[var]+b, linewidth = 2)\n",
    "    \n",
    "    ax.set_xlabel(xlabels[i])\n",
    "    ax.set_ylabel('IPG Battery [%]')\n",
    "    #ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join(json_path_onedrive, 'results','MultivariateAnal', 'MultiVarScatters'), dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = filtered_corr_df['Telemetry_AllSec_div']\n",
    "y = filtered_corr_df['TEED']\n",
    "\n",
    "plt.scatter(x,y)\n",
    "stats = stats.spearmanr(x,y, nan_policy = 'omit')\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test assumptions for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Assumptions:\n",
    "import seaborn as sns\n",
    "\n",
    "#1. Linearity and \n",
    "residuals = model2.resid\n",
    "fitted_values = model2.fittedvalues\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].scatter(fitted_values, residuals)\n",
    "axs[0].set_xlabel('Fitted Values')\n",
    "axs[0].set_ylabel('Residuals')\n",
    "axs[0].set_title('Residuals vs. Fitted Values Plot')\n",
    "\n",
    "#Interpretation: Check for a random scatter of points with no discernible pattern. \n",
    "# A pattern may indicate non-linearity or heteroscedasticity.\n",
    "\n",
    "#2. Homoscedasticity\n",
    "axs[1].scatter(fitted_values, abs(np.sqrt(np.abs(residuals))))\n",
    "axs[1].set_xlabel('Fitted Values')\n",
    "axs[1].set_ylabel('Square Root of Standardized Residuals')\n",
    "axs[1].set_title('Scale-Location Plot')\n",
    "plt.show()\n",
    "#Interpretation: Check for a horizontal line with no clear pattern. \n",
    "# A funnel-shaped pattern may indicate heteroscedasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Normality of Residuals\n",
    "sm.qqplot(residuals, line='s')\n",
    "#Interpretation: Points close to the diagonal \n",
    "# line suggest that residuals are approximately normally distributed.\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "stat, p_value = shapiro(residuals)\n",
    "\n",
    "print(f'Shapiro-Wilk Test Statistic: {stat:.4f}, p-value: {p_value:.4f}')\n",
    "#small p-value suggests that the residuals are not normally distributed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
