{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from importlib import reload\n",
    "import extract_features\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "json_path_project = 'S:\\\\AG\\\\AG-Bewegungsstoerungen-II\\\\LFP\\\\PROJECTS\\BATTERY\\\\'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing all Json files from Directory, and extracting the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path_Subject = 'Sub047\\\\Ward'\n",
    "\n",
    "all_json_files = glob.glob(os.path.join(json_path_project, json_path_Subject, '*.json'))\n",
    "filtered_files = [file for file in all_json_files if not os.path.basename(file).startswith('MetaTable') and not os.path.basename(file).startswith('Sub')]\n",
    "filtered_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''with open(os.path.join(json_path, 'Report_Json_Session_Report_20200605T115803.json')) as file:\n",
    "            # Load the JSON data\n",
    "            data = json.load(file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(extract_features)\n",
    "SUBID = json_path_Subject.split('\\\\', 1)[0]\n",
    "json_path = os.path.join(json_path_project, json_path_Subject)\n",
    "extract_features.extract_MetaTable(json_path_Subject, json_path, SUBID, filtered_files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Merging all Dataframes together for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mySub = SUBID\n",
    "All_MetaTables_ThisSub_path = os.path.join(json_path_project, mySub)\n",
    "\n",
    "# Initialize an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Iterate through the files in the directory\n",
    "for filename in os.listdir(All_MetaTables_ThisSub_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(All_MetaTables_ThisSub_path, filename)\n",
    "        \n",
    "        # Read the JSON file and append the DataFrame to the list\n",
    "        df = pd.read_json(file_path)\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "All_MetaTables_ThisSub_Combined = pd.concat(dfs, ignore_index=True)\n",
    "conversion_factor = 24 * 60 * 60\n",
    "All_MetaTables_ThisSub_Combined['AccumulatedTherapyOnTimeSinceImplant_Initial_Days'] = All_MetaTables_ThisSub_Combined['AccumulatedTherapyOnTimeSinceImplant_Initial'] / conversion_factor\n",
    "All_MetaTables_ThisSub_Combined.sort_values('AccumulatedTherapyOnTimeSinceImplant_Initial', inplace=True)\n",
    "All_MetaTables_ThisSub_Combined.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''All_MetaTables_ThisSub_Combined = pd.read_json(os.path.join(\n",
    "    'C:\\\\Users\\\\mathiopv\\\\OneDrive - Charité - Universitätsmedizin Berlin\\\\BATTERY_LIFE\\\\results\\\\MetaTable_Alls',\n",
    "    'Sub005_MetaTable_All.json'\n",
    "))\n",
    "\n",
    "All_MetaTables_ThisSub_Combined.head()'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Curating the Merged Df: Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = All_MetaTables_ThisSub_Combined.duplicated(subset=['SessionDate', 'AccumulatedTherapyOnTimeSinceImplant_Initial'], keep=False)\n",
    "duplicate_indices = duplicates[duplicates].index.tolist()\n",
    "duplicate_rows = All_MetaTables_ThisSub_Combined[duplicates]\n",
    "\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_MetaTables_ThisSub_Combined.drop_duplicates(subset=['SessionDate', 'AccumulatedTherapyOnTimeSinceImplant_Initial'], keep='first', inplace=True)\n",
    "All_MetaTables_ThisSub_Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Get the last row of 'BatteryPercentage' for each unique 'Con_Reason' value\n",
    "last_battery_percentages = All_MetaTables_ThisSub_Combined.groupby('Con_Reason')['BatteryPercentage'].last()\n",
    "\n",
    "# Calculate the sum of 'overallSensingDurSec' for each unique 'Con_Reason' value\n",
    "sum_sensing_duration = All_MetaTables_ThisSub_Combined.groupby('Con_Reason')['overallSensingDurSec'].sum()/60\n",
    "sum_telemetry_duration = All_MetaTables_ThisSub_Combined.groupby('Con_Reason')['telemetry_durationSec'].sum()/60\n",
    "\n",
    "# Iterate through unique 'Con_Reason' values\n",
    "for con_reason in All_MetaTables_ThisSub_Combined['Con_Reason'].unique():\n",
    "    print(f\"Last Battery Percentage for {con_reason}: {last_battery_percentages[con_reason]}\")\n",
    "    print(f\"Sum of overallSensingDurSec for {con_reason}: {sum_sensing_duration[con_reason]}\")\n",
    "    print(f\"Sum of telemetry_durationSec for {con_reason}: {sum_telemetry_duration[con_reason]}\")\n",
    "    print()'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Curating the Merged Df: Determine Follow-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''%matplotlib qt\n",
    "plt.scatter(All_MetaTables_ThisSub_Combined['AccumulatedTherapyOnTimeSinceImplant_Initial_Days'], All_MetaTables_ThisSub_Combined['BatteryPercentage'])\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''postOp_cutoff = 50\n",
    "fu3m_cutoff = 120\n",
    "fu12_cutoff = 360\n",
    "\n",
    "All_MetaTables_ThisSub_Combined.loc[\n",
    "    All_MetaTables_ThisSub_Combined['AccumulatedTherapyOnTimeSinceImplant_Initial_Days'] < postOp_cutoff, 'FollowUp'] = 'FU0M'\n",
    "\n",
    "All_MetaTables_ThisSub_Combined.loc[\n",
    "    (All_MetaTables_ThisSub_Combined['AccumulatedTherapyOnTimeSinceImplant_Initial_Days'] > postOp_cutoff) &\n",
    "    (All_MetaTables_ThisSub_Combined['AccumulatedTherapyOnTimeSinceImplant_Initial_Days'] < fu3m_cutoff), 'FollowUp'] = 'FU3M'\n",
    "\n",
    "All_MetaTables_ThisSub_Combined.loc[\n",
    "    All_MetaTables_ThisSub_Combined['AccumulatedTherapyOnTimeSinceImplant_Initial_Days'] > fu3m_cutoff, 'FollowUp'] = 'FU12M'\n",
    "\n",
    "All_MetaTables_ThisSub_Combined.loc[\n",
    "All_MetaTables_ThisSub_Combined['AccumulatedTherapyOnTimeSinceImplant_Initial_Days'] > fu12_cutoff, 'FollowUp'] = 'LongTerm'\n",
    "\n",
    "All_MetaTables_ThisSub_Combined.loc[\n",
    "    All_MetaTables_ThisSub_Combined['Con_Reason'] == 'Beelitz', 'FollowUp'] = 'Beelitz'\n",
    "\n",
    "# Calculate mean of 'overallSensingDurSec' for rows where 'Con_Reason' is 'Ambulant'\n",
    "mean_dur = All_MetaTables_ThisSub_Combined.loc[All_MetaTables_ThisSub_Combined['Con_Reason'] == 'Ambulant', 'overallSensingDurSec'].mean()\n",
    "mean_dur1 = All_MetaTables_ThisSub_Combined.loc[All_MetaTables_ThisSub_Combined['Con_Reason'] == 'TAmbulant', 'overallSensingDurSec'].mean()\n",
    "\n",
    "# Update 'Con_Reason' column based on the mean value\n",
    "All_MetaTables_ThisSub_Combined.loc[All_MetaTables_ThisSub_Combined['Con_Reason'] == 'Ambulant', 'Con_Reason'] = \\\n",
    "    All_MetaTables_ThisSub_Combined.loc[All_MetaTables_ThisSub_Combined['Con_Reason'] == 'Ambulant'].apply(lambda row: 'Forschung' if row['overallSensingDurSec'] >= 10 else 'Ward', axis=1)\n",
    "\n",
    "All_MetaTables_ThisSub_Combined.loc[All_MetaTables_ThisSub_Combined['Con_Reason'] == 'TAmbulant', 'Con_Reason'] = \\\n",
    "    All_MetaTables_ThisSub_Combined.loc[All_MetaTables_ThisSub_Combined['Con_Reason'] == 'TAmbulant'].apply(lambda row: 'Forschung' if row['overallSensingDurSec'] >= 10 else 'Ward', axis=1)\n",
    "\n",
    "\n",
    "#All_MetaTables_ThisSub_Combined['Con_Reason'] = All_MetaTables_ThisSub_Combined['Con_Reason'].apply(lambda x: 'Forschung' if x == 'True' else 'Ward')\n",
    "All_MetaTables_ThisSub_Combined.head(20)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All_MetaTables_ThisSub_Combined.at[35, 'telemetry_durationSec'] = np.nan\n",
    "\n",
    "'''[datetime.strptime(t, \"%Y-%m-%dT%H:%M:%SZ\") for t in All_MetaTables_ThisSub_Combined['SessionDate']]\n",
    "arr_timestamps\n",
    "\n",
    "import 3m timestamp\n",
    "i_3mfu = np.argmin(abs(arr_timestamps - 3m_time))'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If all is Ok, save Dataframe Now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetaTable_Results_Path = 'C:\\\\Users\\\\mathiopv\\\\OneDrive - Charité - Universitätsmedizin Berlin\\\\BATTERY_LIFE\\\\results\\\\MetaTable_Alls'\n",
    "\n",
    "All_MetaTables_ThisSub_Combined.to_json(os.path.join(\n",
    "    MetaTable_Results_Path,\n",
    "    f'{mySub}_MetaTable_All.json'), \n",
    "    orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Convert the json files to excels in order to fix FU\n",
    "\n",
    "MetaTable_Results_Path = 'C:\\\\Users\\\\mathiopv\\\\OneDrive - Charité - Universitätsmedizin Berlin\\\\BATTERY_LIFE\\\\results\\\\MetaTable_Alls'\n",
    "\n",
    "json_files = [f for f in os.listdir(MetaTable_Results_Path) if f.endswith('.json')]\n",
    "\n",
    "for json_file in json_files:\n",
    "    # Read the JSON file into a dataframe\n",
    "    json_path = os.path.join(MetaTable_Results_Path, json_file)\n",
    "    df = pd.read_json(json_path)\n",
    "    \n",
    "    # Extract the filename without the extension\n",
    "    file_name_without_extension, _ = os.path.splitext(json_file)\n",
    "    \n",
    "    # Create the Excel file path\n",
    "    excel_file = os.path.join(MetaTable_Results_Path, file_name_without_extension + '.xlsx')\n",
    "    \n",
    "    # Save the dataframe as an Excel file\n",
    "    df.to_excel(excel_file, index=False)\n",
    "    print(f\"Converted {json_file} to {file_name_without_extension}.xlsx\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Make average features for each follow-up and save them + Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\mathiopv\\\\OneDrive - Charité - Universitätsmedizin Berlin\\\\BATTERY_LIFE\\\\results\\\\MetaTable_Alls'\n",
    "results_path_object = 'C:\\\\Users\\\\mathiopv\\\\OneDrive - Charité - Universitätsmedizin Berlin\\\\BATTERY_LIFE\\\\results\\\\Avg_Features'\n",
    "figures_path_object = 'C:\\\\Users\\\\mathiopv\\\\OneDrive - Charité - Universitätsmedizin Berlin\\\\BATTERY_LIFE\\\\figures\\\\Overview\\\\'\n",
    "\n",
    "\n",
    "file_list = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('Sub024_MetaTable_All.xlsx') or filename.endswith('Sub024_MetaTable_All.xlsx'):  # Filter Excel files\n",
    "        file_list.append(filename)\n",
    "\n",
    "for filename in file_list:\n",
    "\n",
    "    All_MetaTables_ThisSub_Combined = pd.read_excel(os.path.join(path, filename))\n",
    "\n",
    "    sub_id = filename[0:6]\n",
    "\n",
    "    sums = pd.DataFrame(columns=['TimePoint', 'Telemetry_AllSec', 'TelemDurSumSecRes','TelemDurSumSecWard','SensDurSumSec', 'FirstBatVal', 'LastBatVal'])\n",
    "    # Get the unique time points in the order they appear\n",
    "    time_points_sorted = All_MetaTables_ThisSub_Combined['FollowUp'].unique()\n",
    "\n",
    "    # Sort the time points based on their first occurrence in the DataFrame\n",
    "    #time_points_sorted = sorted(time_points, key=lambda x: np.where(All_MetaTables_ThisSub_Combined['FollowUp'] == x)[0][0])\n",
    "\n",
    "    # Get the corresponding y-values (last battery values)\n",
    "    first_battery_values = All_MetaTables_ThisSub_Combined.groupby('FollowUp')['BatteryPercentage'].first()\n",
    "    last_battery_values = All_MetaTables_ThisSub_Combined.groupby('FollowUp')['BatteryPercentage'].last()\n",
    "    #y_values = [last_battery_values[tp] if tp in last_battery_values.index else 0 for tp in time_points_sorted]\n",
    "\n",
    "\n",
    "    for tp in time_points_sorted:\n",
    "        subset = All_MetaTables_ThisSub_Combined[All_MetaTables_ThisSub_Combined['FollowUp'] == tp]\n",
    "        telemetry_all = subset['telemetry_durationSec'].sum()\n",
    "        telemetry_sumRes = subset.loc[subset['Con_Reason'] == 'Forschung', 'telemetry_durationSec'].sum()\n",
    "        telemetry_sumWard = subset.loc[(subset['Con_Reason'] == 'Ward') | (subset['Con_Reason'] == 'Beelitz'), 'telemetry_durationSec'].sum()\n",
    "        sensing_sum = subset['overallSensingDurSec'].sum()\n",
    "        first_battery_value = first_battery_values[tp] if tp in first_battery_values.index else None\n",
    "        last_battery_value = last_battery_values[tp] if tp in last_battery_values.index else None\n",
    "        \n",
    "        sums = sums.append({\n",
    "            'TimePoint': tp,\n",
    "            'Telemetry_AllSec': telemetry_all,\n",
    "            'TelemDurSumSecRes': telemetry_sumRes,\n",
    "            'TelemDurSumSecWard': telemetry_sumWard,\n",
    "            'SensDurSumSec': sensing_sum,\n",
    "            'FirstBatVal': first_battery_value,\n",
    "            'LastBatVal': last_battery_value\n",
    "        }, ignore_index=True)\n",
    "\n",
    "    sums.to_csv(os.path.join(\n",
    "    results_path_object,\n",
    "    f'{sub_id}_AvgFeatures.csv'\n",
    "    ))\n",
    "\n",
    "    ####### PLOT IT #######\n",
    "    tp_of_int = ['FU0M','Beelitz','FU3M','FU12M']\n",
    "\n",
    "    # Filter the DataFrame to include only the specified follow-ups\n",
    "    filtered_df = sums [sums ['TimePoint'].isin(tp_of_int)]\n",
    "\n",
    "    %matplotlib inline\n",
    "\n",
    "    fig, axs = plt.subplots(1,4, figsize=(18,4))\n",
    "\n",
    "    axs[0].bar(filtered_df['TimePoint'], filtered_df['Telemetry_AllSec']/60)\n",
    "    axs[0].bar(filtered_df['TimePoint'], filtered_df['TelemDurSumSecRes']/60, label = 'Research')\n",
    "    axs[0].set_ylabel('Duration [min]')\n",
    "    axs[0].set_title('Telemetry Duration')\n",
    "    axs[0].legend()\n",
    "\n",
    "    axs[1].bar(filtered_df['TimePoint'], filtered_df['SensDurSumSec']/60)\n",
    "    axs[1].set_ylabel('Duration [min]')\n",
    "    axs[1].set_title('Sensing Duration')\n",
    "\n",
    "    subset = filtered_df[filtered_df['TimePoint'].isin(['FU0M', 'Beelitz', 'FU3M', 'FU12M'])]\n",
    "    axs[2].bar(subset['TimePoint'], subset['TelemDurSumSecWard']/60)\n",
    "    axs[2].set_ylabel('Duration [min]')\n",
    "    axs[2].set_title('Ward Telemetry')\n",
    "\n",
    "    axs[3].bar(filtered_df['TimePoint'], filtered_df['LastBatVal'])\n",
    "    axs[3].set_ylabel('IPG Battery [%]')\n",
    "    axs[3].set_title('Battery')\n",
    "\n",
    "    plt.suptitle(sub_id)\n",
    "\n",
    "    AvgValues_ThisSub_FigName = f'{sub_id}_Overview'\n",
    "\n",
    "    fig.savefig(os.path.join(\n",
    "        figures_path_object, AvgValues_ThisSub_FigName),\n",
    "        dpi = 150)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Find first 12mfu connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\mathiopv\\\\OneDrive - Charité - Universitätsmedizin Berlin\\\\BATTERY_LIFE\\\\results\\\\MetaTable_Alls'\n",
    "\n",
    "jsons_12mfu = pd.DataFrame(columns=['SubID', 'Con_reason','json_fileName'])\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('.xlsx'):  # Filter Excel files\n",
    "    \n",
    "        thisMetaTable = pd.read_excel(os.path.join(path, filename))\n",
    "        \n",
    "        sub_id = filename[0:6]\n",
    "        fu12m_subset = thisMetaTable[thisMetaTable['FollowUp']=='FU12M']\n",
    "        fu12m_subset = fu12m_subset.reset_index(drop=True)\n",
    "        json_filename = fu12m_subset.loc[0,'json_fileName']\n",
    "        con_reason = fu12m_subset.loc[0,'Con_Reason']\n",
    "        \n",
    "        jsons_12mfu = jsons_12mfu.append({\n",
    "                'SubID': sub_id,\n",
    "                'Con_reason': con_reason,\n",
    "                'json_fileName': json_filename\n",
    "            }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons_12mfu.to_excel(\n",
    "    os.path.join(\n",
    "        path,'Jsons_12mfu_StimPars_ToExtract.xlsx'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
